#!/usr/bin/env python3

"""list contents of all S3 buckets

# Usage:
# 0. setup
# pip install boto3 botocore humanize
#
# 1. Put creds in ~/.aws/credentials, like so:
# [myprofile1]
# aws_access_key_id=...
# aws_secret_access_key=...
# 
# [myprofile2]
# aws_access_key_id=...
# aws_secret_access_key=...
#
# 2. run
# aws-s3-inventory -p myprofile1,myprofile2

Author: Reece Hart, reecehart@gmail.com
License: MIT 
"""

import argparse
import csv
import datetime
import itertools
import json
import logging
import sys

import boto3
import botocore
import humanize
import tqdm

_logger = logging.getLogger()


def parse_args(argv=sys.argv[1:]):
    def flatten_csv_list(l):
        """for a list with possible csv elements, return flattened list with
        csv elements split

        """
        return list(itertools.chain.from_iterable(e.split(",") for e in l))

    ap = argparse.ArgumentParser(
        description=__doc__,
    )
    ap.add_argument("--profiles", "-p",
                    action="append",
                    default=[])

    opts = ap.parse_args(argv)
    opts.profiles = flatten_csv_list(opts.profiles)
    return opts


if __name__ == "__main__":
    import coloredlogs
    coloredlogs.install(level="INFO")

    opts = parse_args()

    fh_out = sys.stdout
    out = csv.writer(fh_out, delimiter="\t")

    for pn in opts.profiles:
        session = boto3.session.Session(profile_name=pn)
        s3 = session.resource("s3")
        for b in list(s3.buckets.iterator())[:5]:
            _logger.debug("{session.profile_name}: S3 bucket {b.name}")
            n = 0
            for obj in b.objects.all():
                n += 1
                out.writerow([
                    pn,
                    obj.bucket_name,
                    obj.key,
                    obj.size,
                    obj.last_modified,
                    obj.storage_class,
                    ])
            _logger.info(f"{b.name}: {n} objects")

#!/usr/bin/env python3
"""summarize activity in named repos"""

import argparse
import csv
import datetime
import itertools
import logging
import math
import os
import re
import subprocess
import sys

import coloredlogs
import git
import maya


_logger = logging.getLogger(__name__)


def get_options(argv):
    ap = argparse.ArgumentParser(
        description=__doc__)

    ap.add_argument("PATHS",
                    nargs="+")
    ap.add_argument(
        "--from-date", "-F",
        required=False,
        default=None)
    ap.add_argument(
        "--to-date", "-T",
        required=False,
        default=None)

    opts = ap.parse_args(argv)
    if opts.from_date:
        opts.from_date = maya.when(opts.from_date).date
    if opts.to_date:
        opts.to_date = maya.when(opts.to_date).date
    return opts


def estimated_time(cmt):
    """estimate time taken for commit"""
    i = cmt.stats.total["insertions"]
    d = cmt.stats.total["deletions"]
    f = cmt.stats.total["files"]
    imd = abs(i - d)
    if imd == 0:
        time = 0
    else:
        time = imd / 200 + (f-1) ** 0.2
        if len(cmt.parents) > 1:              # merge
            time = math.log(time)
        time = max(0.5, time) 
    return time


def commit_summaries(path, opts):
    repo = git.Repo(path)
    basename = os.path.basename(os.path.abspath(path))
    for cmt in repo.iter_commits():
        date = maya.MayaDT(cmt.authored_date).date
        if opts.from_date and date < opts.from_date:
            continue
        if opts.to_date and date >= opts.to_date:
            continue
        if "reece" not in str(cmt.author.author()).lower():
            _logger.warn(f"Skipping commit {cmt.hexsha} by {cmt.author}")
            continue
        d = {
            "date": date,
            "repo": basename,
            "commit": f"'{cmt.hexsha[:8]}",
            "nfiles": cmt.stats.total["files"],
            "del": cmt.stats.total["deletions"],
            "ins": cmt.stats.total["insertions"],
            "time": estimated_time(cmt),
            "message": cmt.summary,
            }
        yield d


def aggregate_commits_daily(commits):
    commits = sorted(commits, key=lambda e: (e["date"], e["repo"]))
    for date, dcommits in itertools.groupby(commits, key=lambda e: e["date"]):
        dcommits = [dc for dc in dcommits if dc["time"] > 0]
        #if (dc["nfiles"] > 1
        #        and (dc["ins"] >= 4 or dc["del"] >= 4)
        #        and not any(w in dc["message"].lower() for w in ("minor",)))
        messages = f"{len(dcommits)} commits:\n" + "\n".join(f"â€¢ {dc['repo']}: {dc['message']}"
                                                             for dc in dcommits)
        yield {
            "date": date,
            "tfiles": sum(dc["nfiles"] for dc in dcommits),
            "tdel": sum(dc["del"] for dc in dcommits),
            "tins": sum(dc["ins"] for dc in dcommits),
            "time": round(sum(dc["time"] for dc in dcommits) * 2) / 2.0,  # nearest 1/2 hour
            "messages": messages
            }
            


if __name__ == "__main__":
    coloredlogs.install()
    _logger.setLevel("DEBUG")

    opts = get_options(sys.argv[1:])

    commits = itertools.chain.from_iterable(commit_summaries(path, opts) for path in opts.PATHS)
    daily_commits = aggregate_commits_daily(commits)

    #fieldnames = "week date repo commit nfiles del ins message".split()
    fieldnames = "date tfiles tdel tins time messages".split()
    ofh = csv.DictWriter(sys.stdout, fieldnames=fieldnames, delimiter="\t")
    ofh.writeheader()
    ofh.writerows(daily_commits)
